{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab82054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chaukt1\\Anaconda3\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Loading liabraries used\n",
    "import os\n",
    "import numpy as np\n",
    "import sdv\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d029796",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv(\"C:/Users/chaukt1/Desktop/rivo/Newflo/PhD2/Geomet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f9a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hole_ID</th>\n",
       "      <th>Depth_From (m)</th>\n",
       "      <th>Depth_To (m)</th>\n",
       "      <th>Bond Work Index  (kWh/t)</th>\n",
       "      <th>Abression Index  (kWh/t)</th>\n",
       "      <th>Rodmill Index  (kWh/t)</th>\n",
       "      <th>Drop Weight index  (kWh/t)</th>\n",
       "      <th>RQD  (%)</th>\n",
       "      <th>Axb (kWh/t)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRED207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRED207</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KRED207</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KRED207</td>\n",
       "      <td>17.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KRED207</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hole_ID  Depth_From (m)  Depth_To (m)  Bond Work Index  (kWh/t)  \\\n",
       "0  KRED207             0.0          10.0                       NaN   \n",
       "1  KRED207            10.0          14.0                      10.3   \n",
       "2  KRED207            14.0          17.2                      12.0   \n",
       "3  KRED207            17.2          27.0                      12.0   \n",
       "4  KRED207            27.0          31.2                      12.0   \n",
       "\n",
       "   Abression Index  (kWh/t)  Rodmill Index  (kWh/t)  \\\n",
       "0                       NaN                     NaN   \n",
       "1                      0.32                    13.7   \n",
       "2                      0.02                    13.8   \n",
       "3                      0.02                    13.8   \n",
       "4                      0.02                    13.8   \n",
       "\n",
       "   Drop Weight index  (kWh/t)  RQD  (%)  Axb (kWh/t)  target  \n",
       "0                         NaN       NaN          NaN       1  \n",
       "1                        21.0     45.00         0.67       1  \n",
       "2                        16.0     54.74         0.32       1  \n",
       "3                        16.0     54.74         0.32       1  \n",
       "4                        16.0     54.74         0.32       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8729aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hole_ID                       False\n",
       "Depth_From (m)                False\n",
       "Depth_To (m)                  False\n",
       "Bond Work Index  (kWh/t)       True\n",
       "Abression Index  (kWh/t)       True\n",
       "Rodmill Index  (kWh/t)         True\n",
       "Drop Weight index  (kWh/t)     True\n",
       "RQD  (%)                       True\n",
       "Axb (kWh/t)                    True\n",
       "target                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a476bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.dropna(subset=['Abression Index  (kWh/t)'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46dc9b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hole_ID                       False\n",
       "Depth_From (m)                False\n",
       "Depth_To (m)                  False\n",
       "Bond Work Index  (kWh/t)      False\n",
       "Abression Index  (kWh/t)      False\n",
       "Rodmill Index  (kWh/t)        False\n",
       "Drop Weight index  (kWh/t)    False\n",
       "RQD  (%)                      False\n",
       "Axb (kWh/t)                   False\n",
       "target                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9d8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels to integer values\n",
    "geo['Hole_ID'] = label_encoder.fit_transform(geo['Hole_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd5a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hole_ID</th>\n",
       "      <th>Depth_From (m)</th>\n",
       "      <th>Depth_To (m)</th>\n",
       "      <th>Bond Work Index  (kWh/t)</th>\n",
       "      <th>Abression Index  (kWh/t)</th>\n",
       "      <th>Rodmill Index  (kWh/t)</th>\n",
       "      <th>Drop Weight index  (kWh/t)</th>\n",
       "      <th>RQD  (%)</th>\n",
       "      <th>Axb (kWh/t)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>54.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hole_ID  Depth_From (m)  Depth_To (m)  Bond Work Index  (kWh/t)  \\\n",
       "1        0            10.0          14.0                      10.3   \n",
       "2        0            14.0          17.2                      12.0   \n",
       "3        0            17.2          27.0                      12.0   \n",
       "4        0            27.0          31.2                      12.0   \n",
       "5        0            31.2          44.0                      12.0   \n",
       "\n",
       "   Abression Index  (kWh/t)  Rodmill Index  (kWh/t)  \\\n",
       "1                      0.32                    13.7   \n",
       "2                      0.02                    13.8   \n",
       "3                      0.02                    13.8   \n",
       "4                      0.02                    13.8   \n",
       "5                      0.02                    13.8   \n",
       "\n",
       "   Drop Weight index  (kWh/t)  RQD  (%)  Axb (kWh/t)  target  \n",
       "1                        21.0     45.00         0.67       1  \n",
       "2                        16.0     54.74         0.32       1  \n",
       "3                        16.0     54.74         0.32       1  \n",
       "4                        16.0     54.74         0.32       1  \n",
       "5                        16.0     54.74         0.32       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c19e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.constraints import FixedCombinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6f68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = FixedCombinations(column_names=['Depth_From (m)', 'Depth_To (m)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca0cdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "met = FixedCombinations(column_names=['Bond Work Index  (kWh/t)',\n",
    "       'Abression Index  (kWh/t)', 'Rodmill Index  (kWh/t)',\n",
    "       'Drop Weight index  (kWh/t)', 'RQD  (%)', 'Axb (kWh/t)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9158f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [Location,met]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2104c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7acc2d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  4.4920,Loss D:  0.0001\n",
      "Epoch 2, Loss G:  4.5135,Loss D: -0.0032\n",
      "Epoch 3, Loss G:  4.5422,Loss D: -0.0033\n",
      "Epoch 4, Loss G:  4.4961,Loss D:  0.0004\n",
      "Epoch 5, Loss G:  4.3850,Loss D: -0.0029\n",
      "Epoch 6, Loss G:  4.3766,Loss D: -0.0053\n",
      "Epoch 7, Loss G:  4.3197,Loss D: -0.0063\n",
      "Epoch 8, Loss G:  4.3152,Loss D: -0.0162\n",
      "Epoch 9, Loss G:  4.3490,Loss D: -0.0096\n",
      "Epoch 10, Loss G:  4.3244,Loss D: -0.0149\n",
      "Epoch 11, Loss G:  4.2806,Loss D: -0.0156\n",
      "Epoch 12, Loss G:  4.4359,Loss D: -0.0120\n",
      "Epoch 13, Loss G:  4.4726,Loss D: -0.0216\n",
      "Epoch 14, Loss G:  4.3086,Loss D: -0.0225\n",
      "Epoch 15, Loss G:  4.2229,Loss D: -0.0207\n",
      "Epoch 16, Loss G:  4.4107,Loss D: -0.0277\n",
      "Epoch 17, Loss G:  4.2820,Loss D: -0.0171\n",
      "Epoch 18, Loss G:  4.2298,Loss D: -0.0144\n",
      "Epoch 19, Loss G:  4.3316,Loss D: -0.0048\n",
      "Epoch 20, Loss G:  4.2721,Loss D: -0.0089\n",
      "Epoch 21, Loss G:  4.3776,Loss D: -0.0284\n",
      "Epoch 22, Loss G:  4.2930,Loss D: -0.0212\n",
      "Epoch 23, Loss G:  4.1587,Loss D: -0.0207\n",
      "Epoch 24, Loss G:  4.1682,Loss D: -0.0306\n",
      "Epoch 25, Loss G:  4.3037,Loss D: -0.0310\n",
      "Epoch 26, Loss G:  4.2759,Loss D: -0.0292\n",
      "Epoch 27, Loss G:  4.2772,Loss D: -0.0335\n",
      "Epoch 28, Loss G:  4.1913,Loss D: -0.0397\n",
      "Epoch 29, Loss G:  4.1881,Loss D: -0.0309\n",
      "Epoch 30, Loss G:  3.9771,Loss D: -0.0336\n",
      "Epoch 31, Loss G:  4.1580,Loss D: -0.0105\n",
      "Epoch 32, Loss G:  4.2392,Loss D:  0.0087\n",
      "Epoch 33, Loss G:  4.2561,Loss D: -0.0083\n",
      "Epoch 34, Loss G:  4.0760,Loss D: -0.0197\n",
      "Epoch 35, Loss G:  4.1223,Loss D: -0.0028\n",
      "Epoch 36, Loss G:  4.0816,Loss D: -0.0083\n",
      "Epoch 37, Loss G:  4.2328,Loss D: -0.0182\n",
      "Epoch 38, Loss G:  4.2450,Loss D: -0.0169\n",
      "Epoch 39, Loss G:  4.0072,Loss D: -0.0168\n",
      "Epoch 40, Loss G:  4.0156,Loss D: -0.0378\n",
      "Epoch 41, Loss G:  4.1598,Loss D: -0.0573\n",
      "Epoch 42, Loss G:  4.1094,Loss D: -0.0416\n",
      "Epoch 43, Loss G:  4.1650,Loss D: -0.0545\n",
      "Epoch 44, Loss G:  4.0813,Loss D: -0.0650\n",
      "Epoch 45, Loss G:  4.0163,Loss D: -0.0596\n",
      "Epoch 46, Loss G:  4.1111,Loss D: -0.0603\n",
      "Epoch 47, Loss G:  4.0804,Loss D: -0.0407\n",
      "Epoch 48, Loss G:  4.0546,Loss D: -0.0295\n",
      "Epoch 49, Loss G:  3.8839,Loss D: -0.0123\n",
      "Epoch 50, Loss G:  4.0571,Loss D: -0.0272\n",
      "Epoch 51, Loss G:  4.0249,Loss D:  0.0059\n",
      "Epoch 52, Loss G:  4.0702,Loss D:  0.0029\n",
      "Epoch 53, Loss G:  3.9915,Loss D:  0.0114\n",
      "Epoch 54, Loss G:  3.8962,Loss D:  0.0083\n",
      "Epoch 55, Loss G:  3.9706,Loss D:  0.0054\n",
      "Epoch 56, Loss G:  3.8520,Loss D:  0.0051\n",
      "Epoch 57, Loss G:  3.8688,Loss D: -0.0094\n",
      "Epoch 58, Loss G:  3.8620,Loss D: -0.0274\n",
      "Epoch 59, Loss G:  3.7543,Loss D: -0.0295\n",
      "Epoch 60, Loss G:  3.7331,Loss D: -0.0317\n",
      "Epoch 61, Loss G:  3.9128,Loss D: -0.0480\n",
      "Epoch 62, Loss G:  3.6667,Loss D: -0.0465\n",
      "Epoch 63, Loss G:  3.8172,Loss D: -0.0377\n",
      "Epoch 64, Loss G:  3.7463,Loss D: -0.0736\n",
      "Epoch 65, Loss G:  3.8152,Loss D: -0.0753\n",
      "Epoch 66, Loss G:  3.8987,Loss D: -0.0784\n",
      "Epoch 67, Loss G:  3.8228,Loss D: -0.0263\n",
      "Epoch 68, Loss G:  3.7766,Loss D: -0.0590\n",
      "Epoch 69, Loss G:  3.7752,Loss D: -0.0396\n",
      "Epoch 70, Loss G:  3.8231,Loss D: -0.0213\n",
      "Epoch 71, Loss G:  3.5849,Loss D: -0.0181\n",
      "Epoch 72, Loss G:  3.6345,Loss D: -0.0015\n",
      "Epoch 73, Loss G:  3.6197,Loss D: -0.0013\n",
      "Epoch 74, Loss G:  3.6594,Loss D:  0.0090\n",
      "Epoch 75, Loss G:  3.5657,Loss D:  0.0038\n",
      "Epoch 76, Loss G:  3.5295,Loss D:  0.0064\n",
      "Epoch 77, Loss G:  3.6663,Loss D:  0.0114\n",
      "Epoch 78, Loss G:  3.3834,Loss D:  0.0226\n",
      "Epoch 79, Loss G:  3.4871,Loss D: -0.0100\n",
      "Epoch 80, Loss G:  3.5546,Loss D:  0.0142\n",
      "Epoch 81, Loss G:  3.6437,Loss D: -0.0003\n",
      "Epoch 82, Loss G:  3.4337,Loss D: -0.0101\n",
      "Epoch 83, Loss G:  3.4654,Loss D: -0.0103\n",
      "Epoch 84, Loss G:  3.5160,Loss D: -0.0025\n",
      "Epoch 85, Loss G:  3.5046,Loss D: -0.0207\n",
      "Epoch 86, Loss G:  3.4451,Loss D: -0.0228\n",
      "Epoch 87, Loss G:  3.2548,Loss D: -0.0426\n",
      "Epoch 88, Loss G:  3.4461,Loss D: -0.0398\n",
      "Epoch 89, Loss G:  3.3993,Loss D: -0.0690\n",
      "Epoch 90, Loss G:  3.5323,Loss D: -0.0673\n",
      "Epoch 91, Loss G:  3.2954,Loss D: -0.0677\n",
      "Epoch 92, Loss G:  3.3903,Loss D: -0.0744\n",
      "Epoch 93, Loss G:  3.4318,Loss D: -0.0513\n",
      "Epoch 94, Loss G:  3.5238,Loss D: -0.0363\n",
      "Epoch 95, Loss G:  3.4391,Loss D: -0.0316\n",
      "Epoch 96, Loss G:  3.4382,Loss D: -0.0330\n",
      "Epoch 97, Loss G:  3.4421,Loss D: -0.0029\n",
      "Epoch 98, Loss G:  3.3442,Loss D: -0.0106\n",
      "Epoch 99, Loss G:  3.0587,Loss D:  0.0276\n",
      "Epoch 100, Loss G:  3.2615,Loss D:  0.0604\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "model = CTGAN(constraints=constraints, generator_dim=(256, 256, 256),\n",
    "              discriminator_dim=(256, 256, 256), batch_size=batch_size, epochs=epochs, verbose=True)\n",
    "model.fit(geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f2189d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling rows: 100%|██████████| 1122/1122 [00:00<00:00, 6213.90it/s]\n"
     ]
    }
   ],
   "source": [
    "n_generated_data = 1122\n",
    "new_geo = model.sample(n_generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfd3b2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846294014988194"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.evaluation import evaluate\n",
    "from sdv.evaluation import evaluate\n",
    "\n",
    "evaluate(new_geo, geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966f0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geo.to_csv('new_geo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fcd7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier F1-scores and their Jaccard similarities::\n",
      "                             f1_real  f1_fake  jaccard_similarity\n",
      "index                                                            \n",
      "DecisionTreeClassifier_fake   0.4444   0.4967              0.3247\n",
      "DecisionTreeClassifier_real   1.0000   0.4771              0.3133\n",
      "LogisticRegression_fake       0.4510   0.5948              0.2000\n",
      "LogisticRegression_real       0.9150   0.4118              0.2750\n",
      "MLPClassifier_fake            0.4902   0.5882              0.2645\n",
      "MLPClassifier_real            0.8954   0.4248              0.3362\n",
      "RandomForestClassifier_fake   0.4575   0.5098              0.3021\n",
      "RandomForestClassifier_real   0.9673   0.4641              0.3304\n",
      "\n",
      "Privacy results:\n",
      "                                         result\n",
      "Duplicate rows between sets (real/fake)  (0, 8)\n",
      "nearest neighbor mean                    0.6058\n",
      "nearest neighbor std                     0.3262\n",
      "\n",
      "Miscellaneous results:\n",
      "                                  Result\n",
      "Column Correlation Distance RMSE  0.2160\n",
      "Column Correlation distance MAE   0.1507\n",
      "\n",
      "Results:\n",
      "                                                result\n",
      "Basic statistics                                0.9807\n",
      "Correlation column correlations                 0.8177\n",
      "Mean Correlation between fake and real columns  0.8899\n",
      "1 - MAPE Estimator results                      0.6413\n",
      "Similarity Score                                0.8324\n"
     ]
    }
   ],
   "source": [
    "from table_evaluator import load_data, TableEvaluator\n",
    "table_evaluator = TableEvaluator(geo, new_geo)\n",
    "table_evaluator.evaluate(target_col='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caebe5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_cumsum = geo.cumsum()\n",
    "fake_data_cumsum = new_geo.cumsum()\n",
    "# Normalize the cumulative sum values between 0 and 1\n",
    "real_data_normalized = real_data_cumsum / real_data_cumsum.max()\n",
    "fake_data_normalized = fake_data_cumsum / fake_data_cumsum.max()\n",
    "\n",
    "# Sort the data points in ascending order for each feature\n",
    "real_data_sorted = geo.apply(lambda col: col.sort_values().values)\n",
    "fake_data_sorted = new_geo.apply(lambda col: col.sort_values().values)\n",
    "\n",
    "# Plot the cumulative sum for each column in separate figures with y-axis range from 0 to 1\n",
    "for column in real_data_normalized.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(real_data_sorted[column], real_data_normalized[column], label=f'Real {column}', marker='o', s=100)\n",
    "    plt.scatter(fake_data_sorted[column], fake_data_normalized[column], label=f'Fake {column}', marker='x', s=100)\n",
    "    plt.xlabel('Column Data', fontsize=18)\n",
    "    plt.ylabel('Cumulative Sum', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(0, 1.05)  # Set y-axis range from 0 to 1\n",
    "    plt.title(f'Cumulative Sum Comparison for {column}', fontsize=20)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278bebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_geo_normalized = (new_geo - new_geo.std()) / new_geo.mean()\n",
    "\n",
    "# Calculate absolute log mean for real_data and fake_data\n",
    "real_data_abs_log_mean = np.log(np.abs(geo_normalized)).mean()\n",
    "fake_data_abs_log_mean = np.log(np.abs(new_geo_normalized)).mean()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "real_mean_values = real_data_abs_log_mean.values\n",
    "fake_mean_values = fake_data_abs_log_mean.values\n",
    "\n",
    "# Plot the absolute log mean comparison for real_data vs fake_data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, real_mean_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, fake_mean_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log'\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right') # Set x-axis ticks at the positions and labels of features\n",
    "plt.ylabel('Absolute Log Mean', fontsize=18)\n",
    "plt.title('Absolute Log Mean Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_geo_normalized = (new_geo - new_geo.std()) / new_geo.mean()\n",
    "# Calculate the absolute log standard deviation for collar DataFrame\n",
    "geo_abs_log_std = np.log(np.abs(geo_normalized )).std()\n",
    "\n",
    "# Calculate the absolute log standard deviation for new_collar DataFrame\n",
    "new_geo_abs_log_std = np.log(np.abs(new_geo_normalized)).std()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "geo_abs_log_std_values = geo_abs_log_std.values\n",
    "new_geo_abs_log_std_values = new_geo_abs_log_std.values\n",
    "\n",
    "# Plot the absolute log standard deviation comparison for collar vs new_collar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, geo_abs_log_std_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, new_geo_abs_log_std_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log' for better visualization\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.ylabel('Absolute Log STD', fontsize=18)\n",
    "plt.title('Absolute Log STD Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25f9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0807a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate real_data and fake_data for PCA\n",
    "all_data = pd.concat([geo, new_geo])\n",
    "\n",
    "# Calculate PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_data)\n",
    "\n",
    "# Separate PCA results for real and fake data\n",
    "real_pca = pca_result[:len(geo)]\n",
    "fake_pca = pca_result[len(new_geo):]\n",
    "\n",
    "# Plot the first two PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(real_pca[:, 0], real_pca[:, 1], label='Real Data', marker='o', s=100)\n",
    "plt.scatter(fake_pca[:, 0], fake_pca[:, 1], label='Fake Data', marker='x', s=100)\n",
    "plt.xlabel('Principal Component 1', fontsize=18)\n",
    "plt.ylabel('Principal Component 2', fontsize=18)\n",
    "plt.title('PCA of Real and Fake Data (CTGAN)', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d782cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import CopulaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5607f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  4.4787,Loss D:  0.0051\n",
      "Epoch 2, Loss G:  4.5384,Loss D:  0.0045\n",
      "Epoch 3, Loss G:  4.5040,Loss D: -0.0023\n",
      "Epoch 4, Loss G:  4.4427,Loss D:  0.0011\n",
      "Epoch 5, Loss G:  4.3357,Loss D: -0.0061\n",
      "Epoch 6, Loss G:  4.5407,Loss D: -0.0035\n",
      "Epoch 7, Loss G:  4.3524,Loss D: -0.0084\n",
      "Epoch 8, Loss G:  4.3534,Loss D: -0.0104\n",
      "Epoch 9, Loss G:  4.3507,Loss D: -0.0087\n",
      "Epoch 10, Loss G:  4.5266,Loss D: -0.0227\n",
      "Epoch 11, Loss G:  4.3691,Loss D: -0.0141\n",
      "Epoch 12, Loss G:  4.3967,Loss D: -0.0286\n",
      "Epoch 13, Loss G:  4.4469,Loss D: -0.0282\n",
      "Epoch 14, Loss G:  4.3804,Loss D: -0.0376\n",
      "Epoch 15, Loss G:  4.3931,Loss D: -0.0412\n",
      "Epoch 16, Loss G:  4.3572,Loss D: -0.0392\n",
      "Epoch 17, Loss G:  4.4478,Loss D: -0.0333\n",
      "Epoch 18, Loss G:  4.3384,Loss D: -0.0425\n",
      "Epoch 19, Loss G:  4.2155,Loss D: -0.0329\n",
      "Epoch 20, Loss G:  4.3867,Loss D: -0.0198\n",
      "Epoch 21, Loss G:  4.3548,Loss D: -0.0245\n",
      "Epoch 22, Loss G:  4.1906,Loss D: -0.0256\n",
      "Epoch 23, Loss G:  4.2660,Loss D: -0.0243\n",
      "Epoch 24, Loss G:  4.2095,Loss D: -0.0171\n",
      "Epoch 25, Loss G:  4.3060,Loss D: -0.0063\n",
      "Epoch 26, Loss G:  4.3608,Loss D: -0.0096\n",
      "Epoch 27, Loss G:  4.1410,Loss D: -0.0173\n",
      "Epoch 28, Loss G:  4.1899,Loss D: -0.0166\n",
      "Epoch 29, Loss G:  4.2089,Loss D: -0.0286\n",
      "Epoch 30, Loss G:  4.0698,Loss D: -0.0219\n",
      "Epoch 31, Loss G:  4.1628,Loss D: -0.0319\n",
      "Epoch 32, Loss G:  4.2218,Loss D: -0.0280\n",
      "Epoch 33, Loss G:  4.1469,Loss D: -0.0230\n",
      "Epoch 34, Loss G:  4.1140,Loss D: -0.0346\n",
      "Epoch 35, Loss G:  4.2430,Loss D: -0.0418\n",
      "Epoch 36, Loss G:  4.2983,Loss D: -0.0422\n",
      "Epoch 37, Loss G:  4.2390,Loss D: -0.0543\n",
      "Epoch 38, Loss G:  4.2902,Loss D: -0.0637\n",
      "Epoch 39, Loss G:  4.2249,Loss D: -0.0539\n",
      "Epoch 40, Loss G:  4.1266,Loss D: -0.0361\n",
      "Epoch 41, Loss G:  4.2603,Loss D: -0.0294\n",
      "Epoch 42, Loss G:  3.8937,Loss D: -0.0385\n",
      "Epoch 43, Loss G:  4.0869,Loss D: -0.0025\n",
      "Epoch 44, Loss G:  4.1504,Loss D: -0.0033\n",
      "Epoch 45, Loss G:  4.0680,Loss D:  0.0001\n",
      "Epoch 46, Loss G:  4.0847,Loss D: -0.0277\n",
      "Epoch 47, Loss G:  3.9540,Loss D:  0.0305\n",
      "Epoch 48, Loss G:  3.9858,Loss D:  0.0229\n",
      "Epoch 49, Loss G:  4.0430,Loss D:  0.0223\n",
      "Epoch 50, Loss G:  3.9842,Loss D:  0.0027\n",
      "Epoch 51, Loss G:  4.0154,Loss D: -0.0035\n",
      "Epoch 52, Loss G:  3.9722,Loss D: -0.0119\n",
      "Epoch 53, Loss G:  4.0473,Loss D: -0.0203\n",
      "Epoch 54, Loss G:  3.8359,Loss D: -0.0103\n",
      "Epoch 55, Loss G:  3.9980,Loss D: -0.0171\n",
      "Epoch 56, Loss G:  3.9326,Loss D: -0.0414\n",
      "Epoch 57, Loss G:  3.9171,Loss D: -0.0287\n",
      "Epoch 58, Loss G:  3.8729,Loss D: -0.0446\n",
      "Epoch 59, Loss G:  3.9964,Loss D: -0.0299\n",
      "Epoch 60, Loss G:  3.9233,Loss D: -0.0514\n",
      "Epoch 61, Loss G:  3.9591,Loss D: -0.0473\n",
      "Epoch 62, Loss G:  3.8900,Loss D: -0.0710\n",
      "Epoch 63, Loss G:  3.8948,Loss D: -0.0717\n",
      "Epoch 64, Loss G:  3.9483,Loss D: -0.0440\n",
      "Epoch 65, Loss G:  3.9030,Loss D: -0.0501\n",
      "Epoch 66, Loss G:  3.9679,Loss D: -0.0539\n",
      "Epoch 67, Loss G:  3.9630,Loss D: -0.0492\n",
      "Epoch 68, Loss G:  3.6358,Loss D: -0.0450\n",
      "Epoch 69, Loss G:  3.7520,Loss D: -0.0108\n",
      "Epoch 70, Loss G:  3.7982,Loss D: -0.0203\n",
      "Epoch 71, Loss G:  3.6611,Loss D:  0.0001\n",
      "Epoch 72, Loss G:  3.7833,Loss D:  0.0054\n",
      "Epoch 73, Loss G:  3.7284,Loss D:  0.0120\n",
      "Epoch 74, Loss G:  3.6483,Loss D:  0.0291\n",
      "Epoch 75, Loss G:  3.6335,Loss D: -0.0073\n",
      "Epoch 76, Loss G:  3.4575,Loss D:  0.0096\n",
      "Epoch 77, Loss G:  3.5151,Loss D:  0.0091\n",
      "Epoch 78, Loss G:  3.6936,Loss D: -0.0106\n",
      "Epoch 79, Loss G:  3.5356,Loss D: -0.0155\n",
      "Epoch 80, Loss G:  3.6617,Loss D: -0.0154\n",
      "Epoch 81, Loss G:  3.5896,Loss D: -0.0228\n",
      "Epoch 82, Loss G:  3.5791,Loss D: -0.0347\n",
      "Epoch 83, Loss G:  3.4588,Loss D: -0.0497\n",
      "Epoch 84, Loss G:  3.7373,Loss D: -0.0560\n",
      "Epoch 85, Loss G:  3.5425,Loss D: -0.0529\n",
      "Epoch 86, Loss G:  3.3802,Loss D: -0.0607\n",
      "Epoch 87, Loss G:  3.3664,Loss D: -0.0573\n",
      "Epoch 88, Loss G:  3.5779,Loss D: -0.0656\n",
      "Epoch 89, Loss G:  3.3278,Loss D: -0.0470\n",
      "Epoch 90, Loss G:  3.5003,Loss D: -0.0210\n",
      "Epoch 91, Loss G:  3.5667,Loss D: -0.0076\n",
      "Epoch 92, Loss G:  3.5206,Loss D: -0.0277\n",
      "Epoch 93, Loss G:  3.2844,Loss D: -0.0042\n",
      "Epoch 94, Loss G:  3.3777,Loss D:  0.0120\n",
      "Epoch 95, Loss G:  3.3163,Loss D:  0.0156\n",
      "Epoch 96, Loss G:  3.4658,Loss D:  0.0431\n",
      "Epoch 97, Loss G:  3.3741,Loss D:  0.0144\n",
      "Epoch 98, Loss G:  3.3337,Loss D:  0.0070\n",
      "Epoch 99, Loss G:  3.2162,Loss D:  0.0149\n",
      "Epoch 100, Loss G:  3.6533,Loss D: -0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling rows: 100%|██████████| 1122/1122 [00:00<00:00, 4076.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hole_ID</th>\n",
       "      <th>Depth_From (m)</th>\n",
       "      <th>Depth_To (m)</th>\n",
       "      <th>Bond Work Index  (kWh/t)</th>\n",
       "      <th>Abression Index  (kWh/t)</th>\n",
       "      <th>Rodmill Index  (kWh/t)</th>\n",
       "      <th>Drop Weight index  (kWh/t)</th>\n",
       "      <th>RQD  (%)</th>\n",
       "      <th>Axb (kWh/t)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100.8000</td>\n",
       "      <td>107.2000</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>18.9000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>41.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>12.8000</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>12.8000</td>\n",
       "      <td>41.6800</td>\n",
       "      <td>11.7000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>65.5000</td>\n",
       "      <td>70.5000</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>18.9000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>41.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>168.9000</td>\n",
       "      <td>170.0000</td>\n",
       "      <td>15.3000</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>8.9000</td>\n",
       "      <td>6.7000</td>\n",
       "      <td>61.0000</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>137.9000</td>\n",
       "      <td>154.7500</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>54.7400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hole_ID  Depth_From (m)  Depth_To (m)  Bond Work Index  (kWh/t)  \\\n",
       "0       47        100.8000      107.2000                   14.3000   \n",
       "1       64         65.0000       71.0000                   12.8000   \n",
       "2       48         65.5000       70.5000                   14.3000   \n",
       "3       58        168.9000      170.0000                   15.3000   \n",
       "4       37        137.9000      154.7500                   12.0000   \n",
       "\n",
       "   Abression Index  (kWh/t)  Rodmill Index  (kWh/t)  \\\n",
       "0                    0.7800                 18.9000   \n",
       "1                    0.1470                 14.2000   \n",
       "2                    0.7800                 18.9000   \n",
       "3                    0.0310                  8.9000   \n",
       "4                    0.0200                 13.8000   \n",
       "\n",
       "   Drop Weight index  (kWh/t)  RQD  (%)  Axb (kWh/t)  target  \n",
       "0                     11.3000   70.0000      41.1000       1  \n",
       "1                     12.8000   41.6800      11.7000       1  \n",
       "2                     11.3000   70.0000      41.1000       1  \n",
       "3                      6.7000   61.0000       0.7100       1  \n",
       "4                     16.0000   54.7400       0.3200       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CopulaGAN(constraints=constraints,epochs=100,batch_size=1000,\n",
    "                  generator_dim=(256, 256, 256),discriminator_dim=(256, 256, 256),verbose=True)\n",
    "model.fit(geo)\n",
    "new_data = model.sample(1122)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add0e168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier F1-scores and their Jaccard similarities::\n",
      "                             f1_real  f1_fake  jaccard_similarity\n",
      "index                                                            \n",
      "DecisionTreeClassifier_fake   0.3660   0.5229              0.2191\n",
      "DecisionTreeClassifier_real   0.9935   0.5882              0.4101\n",
      "LogisticRegression_fake       0.3856   0.6732              0.0662\n",
      "LogisticRegression_real       0.8954   0.6078              0.4502\n",
      "MLPClassifier_fake            0.3987   0.5490              0.1418\n",
      "MLPClassifier_real            0.9085   0.4510              0.2803\n",
      "RandomForestClassifier_fake   0.3660   0.5621              0.1547\n",
      "RandomForestClassifier_real   0.9935   0.5359              0.3600\n",
      "\n",
      "Privacy results:\n",
      "                                          result\n",
      "Duplicate rows between sets (real/fake)  (0, 14)\n",
      "nearest neighbor mean                     0.5280\n",
      "nearest neighbor std                      0.2963\n",
      "\n",
      "Miscellaneous results:\n",
      "                                  Result\n",
      "Column Correlation Distance RMSE  0.1901\n",
      "Column Correlation distance MAE   0.1271\n",
      "\n",
      "Results:\n",
      "                                                result\n",
      "Basic statistics                                0.9755\n",
      "Correlation column correlations                 0.8635\n",
      "Mean Correlation between fake and real columns  0.9287\n",
      "1 - MAPE Estimator results                      0.5275\n",
      "Similarity Score                                0.8238\n"
     ]
    }
   ],
   "source": [
    "from table_evaluator import load_data, TableEvaluator\n",
    "table_evaluator = TableEvaluator(geo, new_data)\n",
    "table_evaluator.evaluate(target_col='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d408e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_cumsum = geo.cumsum()\n",
    "fake_data_cumsum = new_data.cumsum()\n",
    "# Normalize the cumulative sum values between 0 and 1\n",
    "real_data_normalized = real_data_cumsum / real_data_cumsum.max()\n",
    "fake_data_normalized = fake_data_cumsum / fake_data_cumsum.max()\n",
    "\n",
    "# Sort the data points in ascending order for each feature\n",
    "real_data_sorted = geo.apply(lambda col: col.sort_values().values)\n",
    "fake_data_sorted = new_data.apply(lambda col: col.sort_values().values)\n",
    "\n",
    "# Plot the cumulative sum for each column in separate figures with y-axis range from 0 to 1\n",
    "for column in real_data_normalized.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(real_data_sorted[column], real_data_normalized[column], label=f'Real {column}', marker='o', s=100)\n",
    "    plt.scatter(fake_data_sorted[column], fake_data_normalized[column], label=f'Fake {column}', marker='x', s=100)\n",
    "    plt.xlabel('Column Data', fontsize=18)\n",
    "    plt.ylabel('Cumulative Sum', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(0, 1.05)  # Set y-axis range from 0 to 1\n",
    "    plt.title(f'Cumulative Sum Comparison for {column}', fontsize=20)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55fa515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879077190133551"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.evaluation import evaluate\n",
    "\n",
    "evaluate(new_data, geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b912bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_data_normalized = (new_data - new_data.std()) / new_data.mean()\n",
    "\n",
    "# Calculate absolute log mean for real_data and fake_data\n",
    "real_data_abs_log_mean = np.log(np.abs(geo_normalized)).mean()\n",
    "fake_data_abs_log_mean = np.log(np.abs(new_data_normalized)).mean()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "real_mean_values = real_data_abs_log_mean.values\n",
    "fake_mean_values = fake_data_abs_log_mean.values\n",
    "\n",
    "# Plot the absolute log mean comparison for real_data vs fake_data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, real_mean_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, fake_mean_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log'\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.ylabel('Absolute Log Mean', fontsize=18)\n",
    "plt.title('Absolute Log Mean Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39d3fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_data_normalized = (new_data - new_data.std()) / new_data.mean()\n",
    "# Calculate the absolute log standard deviation for collar DataFrame\n",
    "geo_abs_log_std = np.log(np.abs(geo_normalized )).std()\n",
    "\n",
    "# Calculate the absolute log standard deviation for new_collar DataFrame\n",
    "new_data_abs_log_std = np.log(np.abs(new_data_normalized)).std()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "geo_abs_log_std_values = geo_abs_log_std.values\n",
    "new_data_abs_log_std_values = new_data_abs_log_std.values\n",
    "\n",
    "# Plot the absolute log standard deviation comparison for collar vs new_collar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, geo_abs_log_std_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, new_data_abs_log_std_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log' for better visualization\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.ylabel('Absolute Log STD', fontsize=18)\n",
    "plt.title('Absolute Log STD Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a8140be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate real_data and fake_data for PCA\n",
    "all_data = pd.concat([geo, new_data])\n",
    "\n",
    "# Calculate PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_data)\n",
    "\n",
    "# Separate PCA results for real and fake data\n",
    "real_pca = pca_result[:len(geo)]\n",
    "fake_pca = pca_result[len(new_data):]\n",
    "\n",
    "# Plot the first two PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(real_pca[:, 0], real_pca[:, 1], label='Real Data', marker='o', s=100)\n",
    "plt.scatter(fake_pca[:, 0], fake_pca[:, 1], label='Fake Data', marker='x', s=100)\n",
    "plt.xlabel('Principal Component 1', fontsize=18)\n",
    "plt.ylabel('Principal Component 2', fontsize=18)\n",
    "plt.title('PCA of Real and Fake Data (CopulaGAN)', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ddeaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.tabular import GaussianCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c1e3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling rows: 100%|██████████| 1122/1122 [00:00<00:00, 17976.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hole_ID</th>\n",
       "      <th>Depth_From (m)</th>\n",
       "      <th>Depth_To (m)</th>\n",
       "      <th>Bond Work Index  (kWh/t)</th>\n",
       "      <th>Abression Index  (kWh/t)</th>\n",
       "      <th>Rodmill Index  (kWh/t)</th>\n",
       "      <th>Drop Weight index  (kWh/t)</th>\n",
       "      <th>RQD  (%)</th>\n",
       "      <th>Axb (kWh/t)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>81.0000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>54.7400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>48.2000</td>\n",
       "      <td>75.0000</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>18.9000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>41.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>166.0000</td>\n",
       "      <td>168.9000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>54.7400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>18.9000</td>\n",
       "      <td>11.3000</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>41.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>81.0000</td>\n",
       "      <td>86.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>13.8000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>54.7400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hole_ID  Depth_From (m)  Depth_To (m)  Bond Work Index  (kWh/t)  \\\n",
       "0       19         81.0000       86.0000                   12.0000   \n",
       "1       59         48.2000       75.0000                   14.3000   \n",
       "2       14        166.0000      168.9000                   12.0000   \n",
       "3       18          8.0000       30.0000                   14.3000   \n",
       "4        2         81.0000       86.0000                   12.0000   \n",
       "\n",
       "   Abression Index  (kWh/t)  Rodmill Index  (kWh/t)  \\\n",
       "0                    0.0200                 13.8000   \n",
       "1                    0.7800                 18.9000   \n",
       "2                    0.0200                 13.8000   \n",
       "3                    0.7800                 18.9000   \n",
       "4                    0.0200                 13.8000   \n",
       "\n",
       "   Drop Weight index  (kWh/t)  RQD  (%)  Axb (kWh/t)  target  \n",
       "0                     16.0000   54.7400       0.3200       1  \n",
       "1                     11.3000   70.0000      41.1000       2  \n",
       "2                     16.0000   54.7400       0.3200       2  \n",
       "3                     11.3000   70.0000      41.1000       1  \n",
       "4                     16.0000   54.7400       0.3200       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianCopula(constraints=constraints,\n",
    "                      field_distributions={'RQD  (%)': 'beta'})\n",
    "model.fit(geo)\n",
    "new_data2 = model.sample(1122)\n",
    "new_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e5d85c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717216824854645"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.evaluation import evaluate\n",
    "\n",
    "evaluate(new_data2, geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d4e1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier F1-scores and their Jaccard similarities::\n",
      "                             f1_real  f1_fake  jaccard_similarity\n",
      "index                                                            \n",
      "DecisionTreeClassifier_fake   0.6928   0.6209              0.5612\n",
      "DecisionTreeClassifier_real   1.0000   0.7386              0.5855\n",
      "LogisticRegression_fake       0.7059   0.7255              0.8434\n",
      "LogisticRegression_real       0.9020   0.8954              0.8434\n",
      "MLPClassifier_fake            0.6797   0.6928              0.8773\n",
      "MLPClassifier_real            0.8954   0.7778              0.7486\n",
      "RandomForestClassifier_fake   0.6928   0.6732              0.6452\n",
      "RandomForestClassifier_real   0.9935   0.7778              0.6277\n",
      "\n",
      "Privacy results:\n",
      "                                         result\n",
      "Duplicate rows between sets (real/fake)  (0, 2)\n",
      "nearest neighbor mean                    0.3112\n",
      "nearest neighbor std                     0.2462\n",
      "\n",
      "Miscellaneous results:\n",
      "                                  Result\n",
      "Column Correlation Distance RMSE  0.1535\n",
      "Column Correlation distance MAE   0.0937\n",
      "\n",
      "Results:\n",
      "                                                result\n",
      "Basic statistics                                0.9996\n",
      "Correlation column correlations                 0.9137\n",
      "Mean Correlation between fake and real columns  0.9755\n",
      "1 - MAPE Estimator results                      0.9005\n",
      "Similarity Score                                0.9473\n"
     ]
    }
   ],
   "source": [
    "from table_evaluator import load_data, TableEvaluator\n",
    "table_evaluator = TableEvaluator(geo, new_data2)\n",
    "table_evaluator.evaluate(target_col='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2cf5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_cumsum = geo.cumsum()\n",
    "fake_data_cumsum = new_data2.cumsum()\n",
    "# Normalize the cumulative sum values between 0 and 1\n",
    "real_data_normalized = real_data_cumsum / real_data_cumsum.max()\n",
    "fake_data_normalized = fake_data_cumsum / fake_data_cumsum.max()\n",
    "\n",
    "# Sort the data points in ascending order for each feature\n",
    "real_data_sorted = geo.apply(lambda col: col.sort_values().values)\n",
    "fake_data_sorted = new_data2.apply(lambda col: col.sort_values().values)\n",
    "\n",
    "# Plot the cumulative sum for each column in separate figures with y-axis range from 0 to 1\n",
    "for column in real_data_normalized.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(real_data_sorted[column], real_data_normalized[column], label=f'Real {column}', marker='o', s=100)\n",
    "    plt.scatter(fake_data_sorted[column], fake_data_normalized[column], label=f'Fake {column}', marker='x', s=100)\n",
    "    plt.xlabel('Column Data', fontsize=18)\n",
    "    plt.ylabel('Cumulative Sum', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.ylim(0, 1.05)  # Set y-axis range from 0 to 1\n",
    "    plt.title(f'Cumulative Sum Comparison for {column}', fontsize=20)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b86a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_data2_normalized = (new_data2 - new_data2.std()) / new_data2.mean()\n",
    "\n",
    "# Calculate absolute log mean for real_data and fake_data\n",
    "real_data_abs_log_mean = np.log(np.abs(geo_normalized)).mean()\n",
    "fake_data_abs_log_mean = np.log(np.abs(new_data_normalized)).mean()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "real_mean_values = real_data_abs_log_mean.values\n",
    "fake_mean_values = fake_data_abs_log_mean.values\n",
    "\n",
    "# Plot the absolute log mean comparison for real_data vs fake_data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, real_mean_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, fake_mean_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log'\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.ylabel('Absolute Log Mean', fontsize=18)\n",
    "plt.title('Absolute Log Mean Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45103b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Z-score normalization\n",
    "geo_normalized = (geo - geo.std()) / geo.mean()\n",
    "new_data2_normalized = (new_data2 - new_data2.std()) / new_data2.mean()\n",
    "# Calculate the absolute log standard deviation for collar DataFrame\n",
    "geo_abs_log_std = np.log(np.abs(geo_normalized )).std()\n",
    "\n",
    "# Calculate the absolute log standard deviation for new_collar DataFrame\n",
    "new_data2_abs_log_std = np.log(np.abs(new_data2_normalized)).std()\n",
    "\n",
    "# Prepare data for plotting\n",
    "features = geo.columns\n",
    "geo_abs_log_std_values = geo_abs_log_std.values\n",
    "new_data2_abs_log_std_values = new_data2_abs_log_std.values\n",
    "\n",
    "# Plot the absolute log standard deviation comparison for collar vs new_collar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features, geo_abs_log_std_values, label='Real Data', marker='o', s=100)\n",
    "plt.scatter(features, new_data2_abs_log_std_values, label='Fake Data', marker='x', s=100)\n",
    "plt.yscale('linear')  # Set y-axis scale to 'log' for better visualization\n",
    "plt.xlabel('Features', fontsize=18)\n",
    "plt.ylabel('Absolute Log STD', fontsize=18)\n",
    "plt.title('Absolute Log STD Comparison (Real Data vs Fake Data)', fontsize=20)\n",
    "plt.xticks(range(len(features)), features, fontsize=18, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "236b72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate real_data and fake_data for PCA\n",
    "all_data = pd.concat([geo, new_data])\n",
    "\n",
    "# Calculate PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_data)\n",
    "\n",
    "# Separate PCA results for real and fake data\n",
    "real_pca = pca_result[:len(geo)]\n",
    "fake_pca = pca_result[len(new_data):]\n",
    "\n",
    "# Plot the first two PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(real_pca[:, 0], real_pca[:, 1], label='Real Data', marker='o', s=100)\n",
    "plt.scatter(fake_pca[:, 0], fake_pca[:, 1], label='Fake Data', marker='x', s=100)\n",
    "plt.xlabel('Principal Component 1', fontsize=18)\n",
    "plt.ylabel('Principal Component 2', fontsize=18)\n",
    "plt.title('PCA of Real and Fake Data (GaussianCopula)', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8e0c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = geo.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap with annotated values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f', vmin=-1, vmax=1, cbar=False, annot_kws={\"size\": 14})\n",
    "plt.xticks(fontsize=16, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=16, ha='right')\n",
    "plt.title('ORIGINAL', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd9a31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr1 = new_geo.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap with annotated values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr1, cmap='coolwarm', annot=True, fmt='.2f', vmin=-1, vmax=1, cbar=False, annot_kws={\"size\":14})\n",
    "plt.xticks(fontsize=16, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=16, ha='right')\n",
    "plt.title('CTGAN', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85c0b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr2 = new_data.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap with annotated values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr2, cmap='coolwarm', annot=True, fmt='.2f', vmin=-1, vmax=1, cbar=False, annot_kws={\"size\":14})\n",
    "plt.xticks(fontsize=16, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=16, ha='right')\n",
    "plt.title('CopulaGAN', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c87bfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr3 = new_data2.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap with annotated values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr3, cmap='coolwarm', annot=True, fmt='.2f', vmin=-1, vmax=1, cbar=False, annot_kws={\"size\":14})\n",
    "plt.xticks(fontsize=16, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=16, ha='right')\n",
    "plt.title('GaussianCopula', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94cbf1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef3710a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correlation coefficient between original and CTGAN: 88.37%\n"
     ]
    }
   ],
   "source": [
    "corr_flattened = corr.to_numpy().flatten()\n",
    "corr1_flattened = corr1.to_numpy().flatten()\n",
    "\n",
    "# Compute the Pearson correlation coefficient between the two 1-D arrays\n",
    "r, p = pearsonr(corr_flattened, corr1_flattened)\n",
    "\n",
    "# Calculate the percentage of correlation coefficient\n",
    "percentage_corr = r * 100\n",
    "\n",
    "# Print the percentage of correlation coefficient\n",
    "print(\"Percentage of correlation coefficient between original and CTGAN: {:.2f}%\".format(percentage_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6be26ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correlation coefficient between original and CopulaGAN: 90.47%\n"
     ]
    }
   ],
   "source": [
    "corr_flattened = corr.to_numpy().flatten()\n",
    "corr2_flattened = corr2.to_numpy().flatten()\n",
    "\n",
    "# Compute the Pearson correlation coefficient between the two 1-D arrays\n",
    "r, p = pearsonr(corr_flattened, corr2_flattened)\n",
    "\n",
    "# Calculate the percentage of correlation coefficient\n",
    "percentage_corr = r * 100\n",
    "\n",
    "# Print the percentage of correlation coefficient\n",
    "print(\"Percentage of correlation coefficient between original and CopulaGAN: {:.2f}%\".format(percentage_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f46e62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correlation coefficient between original and GaussianCopula: 94.47%\n"
     ]
    }
   ],
   "source": [
    "corr_flattened = corr.to_numpy().flatten()\n",
    "corr3_flattened = corr3.to_numpy().flatten()\n",
    "\n",
    "# Compute the Pearson correlation coefficient between the two 1-D arrays\n",
    "r, p = pearsonr(corr_flattened, corr3_flattened)\n",
    "\n",
    "# Calculate the percentage of correlation coefficient\n",
    "percentage_corr = r * 100\n",
    "\n",
    "# Print the percentage of correlation coefficient\n",
    "print(\"Percentage of correlation coefficient between original and GaussianCopula: {:.2f}%\".format(percentage_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda98d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
